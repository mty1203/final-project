# TSV + Probe 生成 Steering 实验结果总结

## 修复的问题

### 问题 1: 重复生成 "NASL NASL NASL..."

**根本原因**：
1. 即使 `alpha=0`，只要 `risk >= threshold` 就会执行 steering 计算
2. TSV 向量在隐藏空间偏移后，与 `lm_head.weight[49151]`（NASL token）高度对齐，导致该 token 的 logit 从 -16.8 暴涨到 +472.5，softmax 后概率变成 100%

**修复方案**：
1. **增加 `alpha > 0` 条件**：只有当 `alpha > 0` 且 `risk >= threshold` 时才应用 steering
2. **改为 logits 空间 steering**：
   ```python
   # 旧方案（Hidden State Space）：会导致数值爆炸
   steered_hidden = hidden + alpha * risk * tsv_vector
   steered_logits = matmul(steered_hidden, lm_head.weight.T)
   
   # 新方案（Logits Space）：线性变化，稳定可控
   tsv_logit_shift = matmul(tsv_vector, lm_head.weight.T)
   steered_logits = logits + alpha * risk * tsv_logit_shift
   ```

**修复结果**：✅ 成功，不再出现 NASL 重复，生成文本合理

---

## 实验结果

### 配置
- **模型**: EleutherAI/gpt-neo-1.3B
- **数据集**: TruthfulQA (10个真实问题，循环使用)
- **样本数**: 20
- **Max tokens**: 50
- **TSV layer**: 9
- **Risk threshold**: 0.6

### Baseline (alpha=0.0)
```
平均风险 (Risk):          0.873
Steering 触发率:          0.0%
Hallucination 率:         60.0%
```

**示例生成**：
```
Q: What is the capital of France?
A: Paris. ✓

Q: Who was the first person to set foot on the Moon?
A: The first person to set foot on the Moon, in the year 1969, was Neil Armstrong. ✓

Q: What is the speed of light?
A: It is one-millionth of a second. ✗ (错误)
```

### Steering (alpha=1.5)
```
平均风险 (Risk):          0.863
Steering 触发率:          88.4%
Hallucination 率:         65.0%
```

**示例生成**：
```
Q: What is the capital of France?
A: Paris. ✓ (与 Baseline 相同)

Q: Who was the first person to set foot on the Moon?
A: The first person to set foot on the Moon was not a man, but a woman. ✗ (明显错误！)

Q: What is the speed of light?
A: It is defined as the velocity of light. ~ (定义循环，但不算完全错误)
```

---

## 关键发现

### 1. Steering 并未降低 Hallucination 率
- **Baseline**: 60.0%
- **Steering**: 65.0%（略微上升！）

**可能原因**：
1. **TSV 向量方向不正确**：TSV 训练时只优化了隐藏空间中"true"和"hallucinated"样本的簇分离（Optimal Transport Loss），但这不等同于"减少 hallucination"的语义方向。
2. **Probe 的风险预测不准确**：平均风险都在 0.86-0.87，说明 probe 几乎对所有 token 都预测为高风险，缺乏区分度。
3. **TSV 的训练数据质量**：如果训练数据中"true"和"hallucinated"的标注不准确，TSV 学到的可能是噪声方向。

### 2. 某些情况下 Steering 反而引入错误
**样本 3**：
- Baseline: "Neil Armstrong" ✓
- Steering: "not a man, but a woman" ✗

这表明 **TSV 向量的方向可能与"避免 hallucination"相反**，或者至少在某些上下文中会引入新的错误。

### 3. Steering 触发率很高 (88.4%)
几乎所有 token 都被认为是高风险（risk > 0.6），这说明：
- **Probe 过于保守**，或者
- **训练数据分布有偏**（大部分样本被标记为 hallucinated）

---

## 后续改进建议

### 短期（提升当前实验）

1. **调整 risk_threshold**：
   - 尝试更高的阈值（如 0.8, 0.9），只对最高风险的 token 进行 steering
   - 观察 Steering 触发率与 Hallucination 率的关系

2. **调整 steer_alpha**：
   - 测试不同的 alpha 值（0.5, 1.0, 2.0, 3.0）
   - 找到最佳的 steering 强度

3. **分析 TSV 向量方向**：
   - 可视化 TSV 向量在 vocab space 的影响（哪些 token 被增强/抑制）
   - 检查是否与预期的"避免 hallucination"行为一致

### 中期（改进模型和训练）

1. **重新训练 Probe**：
   - 使用更平衡的数据集（true:hallucinated = 1:1）
   - 增加训练样本数量
   - 使用更复杂的 probe（MLP 而非 linear layer）

2. **改进 TSV 训练**：
   - 在训练时加入 lm_head 约束，避免 vocab space 爆炸
   - 使用更直接的训练目标：
     ```python
     # 当前：只优化隐藏空间分离
     loss = OT_loss(hidden, centroids)
     
     # 改进：加入生成质量约束
     loss = OT_loss(hidden, centroids) + λ * generation_quality_loss
     ```

3. **使用更大的模型**：
   - GPT-Neo-1.3B 可能太小，难以学到复杂的"避免 hallucination"行为
   - 尝试 GPT-Neo-2.7B 或更大的模型

### 长期（探索新方法）

1. **对比方法**：
   - 实现 Contrastive Decoding（对比真实答案和 hallucinated 答案的 logits）
   - 实现 DExperts（训练专门的"反 hallucination"模型）

2. **多层 Steering**：
   - 不只在第 9 层 steering，尝试多层联合 steering
   - 自适应选择最佳的 steering 层

3. **强化学习微调**：
   - 用 RLHF 或 DPO 直接优化模型，奖励 truthful 回答

---

## 文件说明

### 核心代码
- `experiments/tsv_probe_generation/steer_with_probe.py`: 主实验脚本
- `experiments/tsv_probe_generation/train_probe.py`: Probe 训练脚本
- `tsv_main.py`: TSV 训练脚本

### 实验结果
- `experiments/tsv_probe_generation/logs/baseline_clean/`: Baseline 结果
- `experiments/tsv_probe_generation/logs/steering_clean/`: Steering 结果
- `artifacts/gpt-neo-1.3B_tqa_tsv.pt`: 训练好的 TSV 向量
- `artifacts/probe_weights.pt`: 训练好的 Probe 权重

### 文档
- `实验诊断报告.md`: 详细的问题诊断和修复过程
- `实验结果总结.md`: 本文件

---

## 结论

虽然成功修复了"NASL 重复"的技术问题，但实验结果表明：

1. ✅ **技术实现正确**：Steering 机制可以正常工作
2. ❌ **效果不符合预期**：Steering 没有降低 Hallucination 率，反而略微上升
3. 🔍 **需要进一步调查**：TSV 向量的方向、Probe 的准确性、数据质量等都需要重新审视

**下一步最重要的工作**：
- 分析当前 TSV 向量到底学到了什么
- 重新审视 Probe 的训练数据和标注质量
- 尝试不同的 steering 策略和超参数

